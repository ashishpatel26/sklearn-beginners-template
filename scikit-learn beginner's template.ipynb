{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scikit-learn Beginner's Template"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selected Machine Learning References\n",
    "![TODO extend](https://img.shields.io/badge/TODO-extend-orange.svg)\n",
    "\n",
    "### Scikit-learn\n",
    "\n",
    "* Documentation: http://scikit-learn.org/stable/documentation.html\n",
    "* User guide: http://scikit-learn.org/stable/user_guide.html\n",
    "\n",
    "### ML and Python\n",
    "\n",
    "* Python Data Science Handbook, Jake VanderPlas: https://github.com/jakevdp/PythonDataScienceHandbook\n",
    "\n",
    "### ML in general\n",
    "\n",
    "* List of HEP-ML resources: https://github.com/iml-wg/HEP-ML-Resources\n",
    "* Stanford lecture series on Machine Learning by Andrej Karpathy: https://www.youtube.com/playlist?list=PLkt2uSq6rBVctENoVBg1TpCC7OQi31AlC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![TODO explain](https://img.shields.io/badge/TODO-explain-orange.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparatory Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import itertools\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns; sns.set()\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the Higgs data set from https://archive.ics.uci.edu/ml/datasets/HIGGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "attributes = [\n",
    "    'class_label', # 1 for signal, 0 for background\n",
    "    'lepton1_pT',\n",
    "    'lepton1_eta',\n",
    "    'lepton1_phi',\n",
    "    'missing_energy_mag',\n",
    "    'missing_energy_phi',\n",
    "    'jet1_pT',\n",
    "    'jet1_eta',\n",
    "    'jet1_phi',\n",
    "    'jet1_btag',\n",
    "    'jet2_pT',\n",
    "    'jet2_eta',\n",
    "    'jet2_phi',\n",
    "    'jet2_btag',\n",
    "    'jet3_pT',\n",
    "    'jet3_eta',\n",
    "    'jet3_phi',\n",
    "    'jet3_btag',\n",
    "    'jet4_pT',\n",
    "    'jet4_eta',\n",
    "    'jet4_phi',\n",
    "    'jet4_btag',\n",
    "    'm_jj',\n",
    "    'm_jjj',\n",
    "    'm_lv',\n",
    "    'm_jlv',\n",
    "    'm_bb',\n",
    "    'm_wbb',\n",
    "    'm_wwbb'\n",
    "]\n",
    "\n",
    "data = pd.read_csv('./data/higgs/HIGGS.csv',\n",
    "                   header=None,\n",
    "                   sep=',',\n",
    "                   names=attributes,\n",
    "                   usecols=range(0,22),\n",
    "                   nrows=500000)\n",
    "\n",
    "X = data.drop(['class_label'], axis=1)\n",
    "y = (data['class_label']).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('Dimensions of feature matrix X: ', X.shape)\n",
    "print('Dimensions of target vector y:  ', y.shape)\n",
    "\n",
    "print('\\nTotal number of events in data sample: %d' % X.shape[0])\n",
    "print('Number of signal events in data sample: %d (%.2f percent)' % (y[y==1].shape[0], y[y==1].shape[0]*100/y.shape[0]))\n",
    "print('Number of backgr events in data sample: %d (%.2f percent)' % (y[y==0].shape[0], y[y==0].shape[0]*100/y.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![TODO idea](https://img.shields.io/badge/TODO-idea-yellow.svg) _compute correlation matrix (?) ..._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "print('Mean values of transformed data: \\n', scaler.mean_)\n",
    "print('Variance of transformed data: \\n', scaler.scale_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![TODO idea](https://img.shields.io/badge/TODO-idea-yellow.svg) _PCA (?)_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Split Into Training, Validation and Test Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "#                                                    test_size=0.2,\n",
    "#                                                    random_state=42)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, \n",
    "                                                  test_size=0.5,\n",
    "                                                  random_state=42)\n",
    "\n",
    "print('Number of training samples:   %d' % X_train.shape[0])\n",
    "print('Number of validation samples: %d' % X_val.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![TODO idea](https://img.shields.io/badge/TODO-idea-yellow.svg) _prepare data for proper cross-validation_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#default parameter settings\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=750,\n",
    "                             criterion='gini',\n",
    "                             max_depth=None,\n",
    "                             min_samples_split=500,\n",
    "                             min_samples_leaf=1,\n",
    "                             min_weight_fraction_leaf=0.0,\n",
    "                             max_features='auto',\n",
    "                             max_leaf_nodes=None,\n",
    "                             min_impurity_split=1e-07,\n",
    "                             bootstrap=True,\n",
    "                             oob_score=False,\n",
    "                             n_jobs=-1,\n",
    "                             random_state=None,\n",
    "                             verbose=1,\n",
    "                             warm_start=False,\n",
    "                             class_weight=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"Accuracy on training set:   {:.3f}\".format(clf.score(X_train, y_train)))\n",
    "print(\"Accuracy on validation set: {:.3f}\".format(clf.score(X_val, y_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# feature importances\n",
    "\n",
    "importances = clf.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in clf.estimators_],\n",
    "             axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "    \n",
    "# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "    \n",
    "indices_featureNames = np.empty([X_train.shape[1]], dtype=object)\n",
    "    \n",
    "for f in range(X_train.shape[1]):\n",
    "    indices_featureNames[f] = data.columns[indices[f]]\n",
    "    print(\"\\t%d. %s \\t(%f)\" % (f + 1,\n",
    "                               indices_featureNames[f],\n",
    "                               importances[indices[f]]))\n",
    "    \n",
    "plt.figure()\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(X_train.shape[1]),\n",
    "        importances[indices],\n",
    "        color=\"r\",\n",
    "        yerr=std[indices],\n",
    "        align=\"center\")\n",
    "plt.xticks(range(X_train.shape[1]), indices_featureNames, rotation=90)\n",
    "plt.xlim([-1, X_train.shape[1]])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation on the Validation Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_val_score = clf.predict_proba(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MVA output distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_score_val_negClass, y_score_val_posClass = np.split(y_val_score,\n",
    "                                                      2,\n",
    "                                                      axis=1)\n",
    "\n",
    "y_score_val_posClass_truePos = y_score_val_posClass[np.array(y_val==1)]\n",
    "y_score_val_posClass_trueNeg = y_score_val_posClass[np.array(y_val==0)]\n",
    "\n",
    "nbins = 100\n",
    "plt.figure()\n",
    "\n",
    "n_total, bins_total, patches_total = \\\n",
    "    plt.hist(y_val_score[:,1],\n",
    "             bins=nbins,\n",
    "             alpha=.25,\n",
    "             color='black',\n",
    "             label='MVA output')\n",
    "    \n",
    "n_trueNeg, bins_trueNeg, patches_trueNeg = \\\n",
    "    plt.hist(y_score_val_posClass_trueNeg,\n",
    "             bins=nbins,\n",
    "             alpha=0.5,\n",
    "             color='#dd0000',\n",
    "             label='true negative')\n",
    "    \n",
    "n_truePos, bins_truePos, patches_truePos = \\\n",
    "    plt.hist(y_score_val_posClass_truePos,\n",
    "             bins=nbins,\n",
    "             alpha=0.5,\n",
    "             color='green',\n",
    "             label='true positive')\n",
    "    \n",
    "plt.title('MVA output distribution (positive class)')\n",
    "plt.xlim(-0.05, 1.05)\n",
    "plt.xlabel('MVA output')\n",
    "plt.ylabel('Entries')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cut efficiencies plot / MVA cut optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "MVAcut = np.empty((0))\n",
    "\n",
    "plt.figure()\n",
    "fig, ax1 = plt.subplots()\n",
    "signal_efficiency = np.empty((0))\n",
    "backgr_efficiency = np.empty((0))\n",
    "for i in range(nbins):\n",
    "    signal_efficiency = np.append(signal_efficiency, \\\n",
    "                                  np.sum(n_truePos[i:n_truePos.shape[0]]) / np.sum(n_truePos))\n",
    "    backgr_efficiency = np.append(backgr_efficiency, \\\n",
    "                                  np.sum(n_trueNeg[i:n_trueNeg.shape[0]]) / np.sum(n_trueNeg))\n",
    "    MVAcut = np.append(MVAcut, i/(nbins*1.0))\n",
    "l1 = ax1.plot(MVAcut, signal_efficiency, label='signal efficiency', color='blue')\n",
    "l2 = ax1.plot(MVAcut, backgr_efficiency, label='background efficiency', color='red')\n",
    "ax1.set_xlabel('MVA cut')\n",
    "ax1.set_ylabel('Efficiency')\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "significance_per_MVAcut = np.empty((0))\n",
    "for i in range(nbins):\n",
    "    significance_per_MVAcut = np.append(significance_per_MVAcut, \\\n",
    "                                        np.sum(n_truePos[i:n_truePos.shape[0]]) / \\\n",
    "                                        math.sqrt(np.sum(n_truePos[i:n_truePos.shape[0]] + \\\n",
    "                                                         n_trueNeg[i:n_trueNeg.shape[0]])))\n",
    "    \n",
    "l3 = ax2.plot(MVAcut, significance_per_MVAcut,\n",
    "              label='significance',\n",
    "              color='green')\n",
    "pos_max = np.argmax(significance_per_MVAcut)\n",
    "threshold_pos_max = pos_max/(nbins*1.0)\n",
    "l4 = ax2.plot(pos_max/(nbins*1.0), significance_per_MVAcut[pos_max],\n",
    "              label='max. significance for cut at %.2f' % threshold_pos_max,\n",
    "              marker='o', markersize=10, fillstyle='none', mew=2, linestyle='none',\n",
    "              color='#005500')\n",
    "ax2.set_ylabel('Significance', color='green')\n",
    "ax2.tick_params('y', colors='green')\n",
    "\n",
    "plt.title('MVA cut efficiencies')\n",
    "lall = l1+l2+l3+l4\n",
    "labels = [l.get_label() for l in lall]\n",
    "ax2.legend(lall, labels, loc='lower left')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_val, y_val_score[:,1], pos_label=1)\n",
    "roc_auc = roc_auc_score(y_val, y_val_score[:,1])\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label='ROC curve (area = %0.3f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([-0.05, 1.05])\n",
    "plt.ylim([-0.05, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic curve')\n",
    "    \n",
    "# find and plot threshold closest to threshold_pos_max (i.e., the chosen\n",
    "# working point)\n",
    "close_threshold_pos_max = np.argmin(np.abs(thresholds-threshold_pos_max))\n",
    "\n",
    "plt.plot(fpr[close_threshold_pos_max], tpr[close_threshold_pos_max], 'o', markersize=10,\n",
    "        label=\"threshold at %.2f\" % threshold_pos_max, fillstyle=\"none\",\n",
    "        mew=2)\n",
    "\n",
    "plt.legend(loc=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Precision-recall curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "precision = dict()\n",
    "recall = dict()\n",
    "average_precision = dict()\n",
    "\n",
    "precision, recall, thresholds_PRC = \\\n",
    "    precision_recall_curve(y_val,\n",
    "                           y_val_score[:,1])\n",
    "    \n",
    "average_precision = average_precision_score(y_val, y_val_score[:,1])\n",
    "    \n",
    "# Plot Precision-Recall curve\n",
    "n_classes=1\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(recall, precision, lw=2,\n",
    "         label='Precision-recall curve of signal class (area = {1:0.2f})'\n",
    "                ''.format(1, average_precision))\n",
    "\n",
    "# find threshold closest to threshold_pos_max (i.e., the chosen\n",
    "# working point)\n",
    "close_optimum = np.argmin(np.abs(thresholds_PRC-threshold_pos_max))\n",
    "\n",
    "plt.plot(recall[close_optimum], precision[close_optimum],\n",
    "         'o',\n",
    "         markersize=10,\n",
    "         label=\"threshold at %.2f\" % threshold_pos_max,\n",
    "         fillstyle=\"none\",\n",
    "         mew=2)\n",
    "\n",
    "plt.xlim([-0.05, 1.05])\n",
    "plt.ylim([-0.05, 1.05])\n",
    "plt.xlabel(r'Recall $R=T_p / (T_p+F_n)$')\n",
    "plt.ylabel(r'Precision $P=T_p / (T_p+F_p)$')\n",
    "plt.title('Precision-Recall Curve')\n",
    "plt.legend(loc=\"lower right\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \n",
    "    print('Generating confusion matrix...')\n",
    "    \n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes, rotation=45)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Compute confusion matrix\n",
    "y_val_score_labels = (y_val_score[:,1] > threshold_pos_max)\n",
    "cnf_matrix = confusion_matrix(y_val, y_val_score_labels)\n",
    "np.set_printoptions(precision=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix,\n",
    "                      classes=['negative class','positive class'],\n",
    "                      title='Confusion matrix (non-normalized)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix,\n",
    "                      classes=['negative class','positive class'],\n",
    "                      normalize=True,\n",
    "                      title='Normalized confusion matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_val, y_val_score_labels,\n",
    "                            target_names=['negative class','positive class']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Application to the Test Sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MVA output distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ROC curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Precision-recall curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification report"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
